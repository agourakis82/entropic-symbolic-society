{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a2b50058",
   "metadata": {},
   "source": [
    "# 03 â€“ Entropic Embeddings and Cognitive Distances\n",
    "This notebook derives symbolic embeddings from the SWOW graph and connects them to the symbolic manifold $(\\alpha, \\kappa, E_r)$. It uses network embeddings, entropy measures, and topological proximity to operationalize cognitive curvature and symbolic unpredictability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdcb55fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "\n",
    "from node2vec import Node2Vec\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "\n",
    "# Load graph\n",
    "graph_path = pathlib.Path(\"../data/swow_graph.gpickle\")\n",
    "G = nx.read_gpickle(graph_path)\n",
    "print(f\"Graph loaded: {G.number_of_nodes()} nodes, {G.number_of_edges()} edges\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b98594",
   "metadata": {},
   "source": [
    "## Embedding the Graph with Node2Vec\n",
    "We use Node2Vec to learn continuous feature representations for each node based on structural similarity and proximity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc606cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Node2Vec\n",
    "node2vec = Node2Vec(G, dimensions=64, walk_length=30, num_walks=200, workers=2)\n",
    "model = node2vec.fit(window=10, min_count=1)\n",
    "\n",
    "# Create embedding dataframe\n",
    "embedding_df = pd.DataFrame([model.wv[node] for node in G.nodes()], index=list(G.nodes()))\n",
    "embedding_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38b97a2",
   "metadata": {},
   "source": [
    "## Dimensionality Reduction\n",
    "To visualize and use embeddings in symbolic models, we reduce them to 2D or 3D using PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bd751f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA projection\n",
    "pca = PCA(n_components=2)\n",
    "coords = pca.fit_transform(embedding_df)\n",
    "embedding_df[[\"x\", \"y\"]] = coords\n",
    "\n",
    "sns.scatterplot(data=embedding_df, x=\"x\", y=\"y\", alpha=0.3)\n",
    "plt.title(\"Node Embeddings (PCA projection)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a12e42",
   "metadata": {},
   "source": [
    "## Cognitive Symbolic Metrics (Curvature and Entropy)\n",
    "We estimate local entropy and divergence using neighbors of each node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481ccaee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_entropy(node):\n",
    "    neighbors = list(G.neighbors(node))\n",
    "    degs = np.array([G.degree(n) for n in neighbors])\n",
    "    if len(degs) == 0:\n",
    "        return 0\n",
    "    p = degs / degs.sum()\n",
    "    return -(p * np.log2(p)).sum()\n",
    "\n",
    "embedding_df['E_r'] = embedding_df.index.to_series().apply(local_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342e1bf2-d1a9-40cb-b8eb-bcbc7f124609",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
